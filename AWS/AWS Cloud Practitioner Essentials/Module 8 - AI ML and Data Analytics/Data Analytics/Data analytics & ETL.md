### Data analytics

Data analytics is when analysts transform raw historical data to uncover valuable insights and trends. This traditional data analysis can apply to important use cases, such as the following:

- Loan companies explaining lending decisions to customers.
    
- Medical researchers analyzing clinical trial data through hypothesis testing.
    
- Insurance companies making their risk assessment models transparent for regulators.


### Data pipelines for ETL processes

Both AI/ML and traditional data analytics need clean and accessible data in a format that's usable by analytics tools and AI algorithms. ETL processes are used for this purpose. With ETL, you perform the following steps:

1. _Extract_ the data from various sources and store it.
    
2. _Transform_ it into a consistent, usable format for downstream tools to consume.
    
3. _Load_ it into a destination system, like a data warehouse or analytics platform.
    

Data pipelines are automated assembly lines used to make the ETL process efficient and repeatable. AWS has a suite of integrated services so you can build your own data pipelines.

![[Pasted image 20250918203940.png]]![[Pasted image 20250918231605.png]]

![[Pasted image 20250918231630.png]]